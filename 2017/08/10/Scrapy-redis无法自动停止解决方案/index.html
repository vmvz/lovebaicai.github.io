<!DOCTYPE html><html lang="zh-tw"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Scrapy-redis无法自动停止解决方案 · iLovebaicai</title><meta name="description" content="Scrapy-redis无法自动停止解决方案 - Nemo Chen"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://messay.me/atom.xml" title="iLovebaicai"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/cfqtxd1" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/lovebaicai" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="http://messay.me/about/" target="_blank" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Scrapy-redis无法自动停止解决方案</h1><div class="post-info">2017年8月10日</div><div class="post-content"><ul>
<li>公司新项目，需要大量抓取各电商平台的详情页。由于是大量的url，分布式肯定是必须的，故使用Scrapy+redis构造分布式。</li>
<li>经研究Scrapy+Redis源码，以及实际测试来看，scrapy+redis框架在抓取完redis内的source:start_urls后，仍一直读取redis，无法自动停止。</li>
<li><p>解决方法如下，请参考：</p>
<ul>
<li>可以通过engine.close_spider(spider, ‘reason’)来停止程序的运行。在 scrapy-redis/spider的next_requests加入:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">if found == 0:</div><div class="line">        self.crawler.engine.close_spider(&apos;queue is empty, the spider close&apos;)</div></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>监控redis内requests队列，若为空，发送close信号：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">@classmethod</div><div class="line">def from_crawler(cls, crawler, *args, **kwargs):</div><div class="line">      from_crawler = super(SerpSpider, cls).from_crawler</div><div class="line">      spider = from_crawler(crawler, *args, **kwargs)</div><div class="line">      crawler.signals.connect(spider.idle, signal=scrapy.signals.spider_idle)</div><div class="line">      return spider</div><div class="line">  def idle(self):</div><div class="line">      if self.q.llen(self.redis_key) &lt;= 0:</div><div class="line">          self.crawler.engine.close_spider(self, reason=&apos;finished&apos;)</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>参考链接：<ul>
<li><a href="https://segmentfault.com/q/1010000010102034/a-1020000010198313" target="_blank" rel="external">scrapy-redis，爬取全部url结束，不需要清空redis，已设置SCHEDULER_PERSIST = True。</a></li>
<li><a href="https://stackoverflow.com/questions/45540569/the-scrapy-redis-program-does-not-close-automatically" target="_blank" rel="external">The scrapy-redis program does not close automatically</a></li>
</ul>
</li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/2017/08/08/Java判断某年某月多少天/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2017 <a href="http://messay.me">Nemo Chen</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-91949407-1",'auto');ga('send','pageview');</script></body></html>